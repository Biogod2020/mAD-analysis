{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "likely-sister",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Reads assignment & Quality assessment\n",
    "\n",
    "2021-04-15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "above-greene",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import packages \n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from natsort import natsorted\n",
    "from scipy.io import loadmat, savemat\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.color import label2rgb\n",
    "\n",
    "# Customized packages \n",
    "from starmap.sequencing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "invisible-chamber",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get functions \n",
    "\n",
    "from functools import wraps\n",
    "from time import time\n",
    "\n",
    "# Timer\n",
    "def timer(func):\n",
    "    @wraps(func)\n",
    "    def _time_it(*args, **kwargs):\n",
    "        start = int(round(time() * 1000))\n",
    "        try:\n",
    "            return func(*args, **kwargs)\n",
    "        finally:\n",
    "            end_ = int(round(time() * 1000)) - start\n",
    "            end_ = round(end_ / 1000, 4)\n",
    "            print(f\"Total execution time: {end_ if end_ > 0 else 0} s\")\n",
    "    return _time_it\n",
    "\n",
    "\n",
    "# Trim reads \n",
    "@timer\n",
    "def trim_reads(sample_dir, save_as=True):\n",
    "    \n",
    "    print(f\"Trimming reads...\")\n",
    "    current_coordinates = np.loadtxt(os.path.join(sample_dir, 'trim.txt'), dtype=int, delimiter=',')\n",
    "    current_dots = loadmat(os.path.join(sample_dir, 'merged_goodPoints_max3d.mat'))\n",
    "    \n",
    "    # Load reads from matlab data file\n",
    "    bases = [str(i[0][0]) for i in current_dots[\"merged_reads\"]]\n",
    "    bases = np.array(bases)\n",
    "    \n",
    "    # Get reads location\n",
    "    temp = current_dots[\"merged_points\"]\n",
    "    \n",
    "    # Trim reads \n",
    "    to_remove = (temp[:, 0] < current_coordinates[0, 0]) | (temp[:, 0] > current_coordinates[1, 0]) | (temp[:, 1] < current_coordinates[0, 1]) | (temp[:, 1] > current_coordinates[1, 1])\n",
    "    temp = temp[~to_remove, :]\n",
    "    temp[:, 0] = temp[:, 0] - current_coordinates[0, 0]\n",
    "    temp[:, 1] = temp[:, 1] - current_coordinates[0, 1]\n",
    "    bases = bases[~to_remove]\n",
    "\n",
    "    # Save trimmed reads\n",
    "    if save_as:\n",
    "        output_dict = {'trimmed_reads': bases, 'trimmed_points': temp}\n",
    "        savemat(os.path.join(sample_dir, 'trimmed_goodPoints_max3d.mat'), output_dict)\n",
    "\n",
    "    # Convert to 0 indexed and switch axis for python\n",
    "    temp = temp[:, :2]\n",
    "    points = np.zeros(temp.shape)\n",
    "    points[:, 0] = np.round(temp[:, 1]-1)\n",
    "    points[:, 1] = np.round(temp[:, 0]-1)\n",
    "    print(f\"Number of reads: {len(bases)}\")\n",
    "    \n",
    "    return points, bases\n",
    "\n",
    "\n",
    "# Load code book (genes.csv)\n",
    "def load_genes(base_path):\n",
    "    genes2seqs = {}\n",
    "    seqs2genes = {}\n",
    "    with open(os.path.join(base_path, \"genes.csv\"), encoding='utf-8-sig') as f:\n",
    "        for l in f:\n",
    "            fields = l.rstrip().split(\",\")\n",
    "            curr_seg = \"\".join([str(s+1) for s in encode_SOLID(fields[1][::-1])])\n",
    "            curr_seg = curr_seg[5:] + curr_seg[:4]\n",
    "            # print(curr_seg)\n",
    "            genes2seqs[fields[0]] = curr_seg\n",
    "            seqs2genes[genes2seqs[fields[0]]] = fields[0]\n",
    "            \n",
    "    return genes2seqs, seqs2genes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "right-table",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "qualified-given",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AD_mouse9494', 'AD_mouse9723', 'AD_mouse9735', 'AD_mouse9498']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameter\n",
    "points_id = 'max3d'\n",
    "\n",
    "# IO path \n",
    "base_path = './'\n",
    "out_path = os.path.join(base_path, 'output')\n",
    "if not os.path.exists(out_path):\n",
    "    os.mkdir(out_path)\n",
    "    \n",
    "sample_dirs = [d for d in os.listdir(base_path) if d.startswith(\"AD\")]\n",
    "sample_dirs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "undefined-midnight",
   "metadata": {},
   "source": [
    "## Run pipeline for individual sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescription-application",
   "metadata": {},
   "source": [
    "### Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "front-earthquake",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through each sample dir\n",
    "current_dir = sample_dirs[0]\n",
    "# print(current_dir)\n",
    "\n",
    "\n",
    "print(f\"Current sample: {current_dir}\")\n",
    "\n",
    "\n",
    "# Load reads \n",
    "points, bases = trim_reads(current_dir)\n",
    "\n",
    "# Load genes\n",
    "genes2seqs, seqs2genes = load_genes(base_path)\n",
    "\n",
    "# Load dapi label (pi_seg)\n",
    "dapi = load_label_image(os.path.join(current_dir, 'trimmed_images'), fname='pi_sum_seg_011.tif')\n",
    "dapi.shape\n",
    "\n",
    "# Get cell locations \n",
    "centroids = []\n",
    "\n",
    "for i, region in enumerate(regionprops(dapi)):\n",
    "    centroids.append(region.centroid)\n",
    "\n",
    "centroids = np.array(centroids)\n",
    "\n",
    "# Load 2D overlay image \n",
    "overlay = load_nissl_image(os.path.join(current_dir, 'trimmed_images'), fname=\"dots_pi_max_overlay.tif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlled-likelihood",
   "metadata": {},
   "source": [
    "### Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "middle-intensity",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Segmentation\n",
    "seg_out_path = os.path.join(current_dir, 'segmentation')\n",
    "if not os.path.exists(seg_out_path):\n",
    "    os.mkdir(seg_out_path)\n",
    "\n",
    "print(\"Gaussian & Thresholding\")\n",
    "blurred_overlay_seg = gaussian(overlay.astype(np.float), 10)\n",
    "threhold = threshold_otsu(blurred_overlay_seg)\n",
    "\n",
    "# otsu threshold \n",
    "blurred_overlay_seg = blurred_overlay_seg > threhold\n",
    "\n",
    "# manual treshold \n",
    "# blurred_overlay_seg = gaussian(overlay.astype(np.float), 10) > 50\n",
    "\n",
    "# dialation  \n",
    "blurred_overlay_seg = binary_dilation(blurred_overlay_seg, selem=disk(10))\n",
    "\n",
    "print(\"Assigning markers\")\n",
    "centroids = centroids.astype(int)\n",
    "markers = np.zeros(blurred_nissl_seg.shape, dtype=np.uint8)\n",
    "for i in range(centroids.shape[0]):\n",
    "    x, y = centroids[i, :]\n",
    "    if x < blurred_overlay_seg.shape[0] and y < blurred_overlay_seg.shape[1]:\n",
    "        markers[x-1, y-1] = 1\n",
    "markers = ndi.label(markers)[0]\n",
    "\n",
    "print(\"Watershed\")\n",
    "labels = watershed(blurred_overlay_seg, markers, mask=blurred_overlay_seg)\n",
    "labels_line = watershed(blurred_overlay_seg, markers, mask=blurred_overlay_seg, watershed_line=True)\n",
    "\n",
    "print(f\"Labeled {len(np.unique(labels)) - 1} cells\")\n",
    "plt.figure(figsize=(10,20))\n",
    "plt.imshow(label2rgb(labels_line))\n",
    "\n",
    "print(f\"Saving files to {seg_out_path}\")\n",
    "tifffile.imsave(os.path.join(seg_out_path, \"labeled_cells_line.tif\"), labels_line.astype(np.uint16))\n",
    "tifffile.imsave(os.path.join(seg_out_path, \"labeled_cells.tif\"), labels.astype(np.uint16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grand-sullivan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set figure size \n",
    "figsize=(labels_line.shape[1] / 1000 * 5, labels_line.shape[0] / 1000 * 5)\n",
    "\n",
    "# Plot cell number \n",
    "t_size = 10\n",
    "plt.figure(figsize=figsize)\n",
    "plt.imshow(nissl)\n",
    "for i, region in enumerate(regionprops(labels_line)):\n",
    "    plt.plot(region.centroid[1], region.centroid[0], '.', color='red', markersize=4)\n",
    "    plt.text(region.centroid[1], region.centroid[0], str(i), fontsize=t_size, color='red')\n",
    "\n",
    "plt.axis('off')\n",
    "plt.savefig(os.path.join(seg_out_path, \"cell_nums.png\"))\n",
    "plt.clf()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cheap-emergency",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot dots on segmentation mask\n",
    "plt.figure(figsize=figsize)\n",
    "plt.imshow(labels_line > 0, cmap='gray')\n",
    "plt.plot(points[:, 1], points[:, 0], '.', color='red', markersize=1)\n",
    "plt.axis('off')\n",
    "points_seg_path = os.path.join(seg_out_path, \"points_seg.png\")\n",
    "print(f\"Saving points_seg.png\")\n",
    "plt.savefig(points_seg_path)\n",
    "plt.clf()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reserved-proceeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot dots on overlay\n",
    "plt.figure(figsize=figsize)\n",
    "plt.imshow(nissl, cmap='gray')\n",
    "plt.plot(points[:, 1], points[:, 0], '.', color='red', markersize=1)\n",
    "plt.axis('off')\n",
    "points_seg_path = os.path.join(seg_out_path, \"points_nissl.png\")\n",
    "print(f\"Saving points_nissl.png\")\n",
    "plt.savefig(points_seg_path)\n",
    "plt.clf()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intellectual-coast",
   "metadata": {},
   "source": [
    "### Reads assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "european-crown",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Reads assignment to cell\n",
    "expr_out_path = os.path.join(out_path, current_dir)\n",
    "if not os.path.exists(expr_out_path):\n",
    "    os.mkdir(expr_out_path)\n",
    "        \n",
    "points = points.astype(int)\n",
    "reads_assignment = labels[points[:, 0], points[:, 1]]\n",
    "    \n",
    "cell_locs = []\n",
    "total_cells = len(np.unique(labels)) - 1\n",
    "areas = []\n",
    "\n",
    "gene_seqs = seqs2genes.keys()\n",
    "cell_by_barcode = np.zeros((total_cells, len(gene_seqs)))\n",
    "gene_seq_to_index = {}  # map from sequence to index into matrix\n",
    "\n",
    "for i, k in enumerate(gene_seqs):\n",
    "    gene_seq_to_index[k] = i\n",
    "    \n",
    "# Iterate through cells\n",
    "print('Iterate cells...')\n",
    "for i, region in enumerate(regionprops(labels)):\n",
    "    # print(region.label)\n",
    "    areas.append(region.area)\n",
    "    cell_locs.append(region.centroid)\n",
    "    \n",
    "    assigned_reads = bases[np.argwhere(reads_assignment == region.label).flatten()]\n",
    "    for j in assigned_reads:\n",
    "        if j in gene_seq_to_index:\n",
    "            cell_by_barcode[i, gene_seq_to_index[j]] += 1\n",
    "    \n",
    "     \n",
    "# Construct output\n",
    "cell_locs = np.array(cell_locs).astype(int)\n",
    "curr_meta = pd.DataFrame({'sample': current_dir, 'area': areas,\n",
    "                          'x':cell_locs[:, 1], 'y':cell_locs[:, 0]})\n",
    "\n",
    "with open(os.path.join(expr_out_path, \"log.txt\"), 'w') as f:\n",
    "    msg = \"{:.2%} percent [{} out of {}] reads were assigned to {} cells\".format(cell_by_barcode.sum()/len(bases), cell_by_barcode.sum(), len(bases), total_cells)\n",
    "    print(msg)\n",
    "    f.write(msg)\n",
    "np.savetxt(os.path.join(expr_out_path, \"cell_barcode_count.csv\"), cell_by_barcode.astype(np.int), delimiter=',', fmt=\"%d\")\n",
    "cell_barcode_names = pd.DataFrame({'seq': list(seqs2genes.keys()), 'gene': list(seqs2genes.values())})\n",
    "cell_barcode_names.to_csv(os.path.join(expr_out_path, \"cell_barcode_names.csv\"), header=False)\n",
    "curr_meta.to_csv(os.path.join(expr_out_path, \"meta.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accredited-necklace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview current metadata\n",
    "curr_meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rotary-conspiracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot area distribution\n",
    "sns.distplot(areas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "active-dayton",
   "metadata": {},
   "source": [
    "### Reads pattern visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerical-decision",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get assigned reads \n",
    "assigned_index = np.argwhere(reads_assignment != 0).flatten()\n",
    "assigned_bases = bases[assigned_index]\n",
    "assigned_points = points[assigned_index, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empty-design",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get reads of specific gene\n",
    "gene = 'PPP1R9B'\n",
    "curr_index = np.argwhere(assigned_bases == genes2seqs[gene]).flatten()\n",
    "curr_points = assigned_points[curr_index, :]\n",
    "print(f\"Number of reads: {curr_points.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minimal-eclipse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot dots on segmentation mask\n",
    "plt.figure(figsize=figsize)\n",
    "plt.imshow(nissl, cmap='gray')\n",
    "plt.plot(curr_points[:, 1], curr_points[:, 0], '.', color='red', markersize=1)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "built-level",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get read quantification for each gene after read assignemnt and got the top-20\n",
    "per_gene_expr = pd.DataFrame({'gene': list(seqs2genes.values()), 'expr': cell_by_barcode.sum(axis=0)})\n",
    "per_gene_expr = per_gene_expr.sort_values('expr', ascending=False, ignore_index=True)\n",
    "\n",
    "# Get top 20 genes & Curated markers \n",
    "top20 = per_gene_expr.head(20).gene.to_list()\n",
    "curated = ['SLC17A7', 'CUX2', 'RORB', 'SULF2', 'PCP4',\n",
    "          'GAD1', 'PVALB', 'SST', 'NPY', 'VIP', 'MBP', 'MOBP']\n",
    "selected_genes = top20 + curated\n",
    "selected_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affected-light",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate reads pattern plot for all the selected genes \n",
    "expr_figure_out_path = os.path.join(expr_out_path, 'figures')\n",
    "if not os.path.exists(expr_figure_out_path):\n",
    "    os.mkdir(expr_figure_out_path)\n",
    "    \n",
    "for i, gene in enumerate(selected_genes):\n",
    "    \n",
    "    curr_index = np.argwhere(assigned_bases == genes2seqs[gene]).flatten()\n",
    "    curr_points = assigned_points[curr_index, :]\n",
    "    n_reads = curr_points.shape[0]\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(nissl, cmap='gray')\n",
    "    plt.plot(curr_points[:, 1], curr_points[:, 0], '.', color='red', markersize=1)\n",
    "    plt.axis('off')\n",
    "    expr_figure_path = os.path.join(expr_figure_out_path, f\"{i+1}.{gene}_{n_reads}.png\")\n",
    "    plt.savefig(expr_figure_path)\n",
    "    plt.clf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strong-frequency",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Generate complete matrix\n",
    "\n",
    "*run this after finishing assignments for all samples*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subtle-divide",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct complete matrix\n",
    "cell_by_gene_complete = None\n",
    "meta_complete = None\n",
    "\n",
    "for i, d in enumerate(sample_dirs):\n",
    "    print(f\"Loading sample: {d}\")\n",
    "    current_expr_path = os.path.join(out_path, d)\n",
    "    current_expr = np.loadtxt(os.path.join(current_expr_path, \"cell_barcode_count.csv\"), dtype=int, delimiter=',')\n",
    "    current_meta = pd.read_csv(os.path.join(current_expr_path, \"meta.csv\"))\n",
    "    \n",
    "    # add to complete matrix\n",
    "    if cell_by_gene_complete is not None:\n",
    "        cell_by_gene_complete = np.concatenate((cell_by_gene_complete, current_expr))\n",
    "    else:\n",
    "        cell_by_gene_complete = current_expr\n",
    "        \n",
    "    if meta_complete is not None:\n",
    "        meta_complete = pd.concat([meta_complete, current_meta])\n",
    "    else:\n",
    "        meta_complete = current_meta\n",
    "        \n",
    "np.savetxt(os.path.join(out_path, \"complete_cell_barcode_count.csv\"), cell_by_gene_complete.astype(np.int), delimiter=',', fmt=\"%d\")\n",
    "meta_complete = meta_complete.reset_index(drop=True)\n",
    "meta_complete = meta_complete.rename(columns={\"Unnamed: 0\": \"orig_index\"})\n",
    "meta_complete.to_csv(os.path.join(out_path, \"complete_meta.csv\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
